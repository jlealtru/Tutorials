{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.text import * \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import io\n",
    "import os\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "# https://www.consumerfinance.gov/data-research/hmda/\n",
    "\n",
    "base_path = '/home/datawrestler/data/financial'\n",
    "fname = 'financial.csv'\n",
    "full_path = os.path.join(base_path, fname)\n",
    "\n",
    "df = pd.read_csv(full_path, low_memory=False)\n",
    "# shuffle the inputs\n",
    "df = df.sample(n=df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_complaints = df.loc[df['Consumer complaint narrative'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product\n",
       "Bank account or service                                                         14885\n",
       "Checking or savings account                                                     11609\n",
       "Consumer Loan                                                                    9474\n",
       "Credit card                                                                     18838\n",
       "Credit card or prepaid card                                                     19356\n",
       "Credit reporting                                                                31588\n",
       "Credit reporting, credit repair services, or other personal consumer reports    84426\n",
       "Debt collection                                                                 82260\n",
       "Money transfer, virtual currency, or money service                               5004\n",
       "Money transfers                                                                  1497\n",
       "Mortgage                                                                        51282\n",
       "Other financial service                                                           292\n",
       "Payday loan                                                                      1747\n",
       "Payday loan, title loan, or personal loan                                        3949\n",
       "Prepaid card                                                                     1450\n",
       "Student loan                                                                    20585\n",
       "Vehicle loan or lease                                                            5172\n",
       "Virtual currency                                                                   16\n",
       "Name: Complaint ID, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a sense for the totla number of possible complaint issues\n",
    "consumer_complaints.groupby('Product')['Complaint ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets focus on bank account, credit card, student loan, and money transfers\n",
    "\n",
    "cats = ['Bank account or service', 'Credit card', 'Student loan' ,\n",
    "       'Money transfers']\n",
    "\n",
    "keep_cols = ['Product', 'Complaint ID', 'Consumer complaint narrative']\n",
    "\n",
    "traindata = consumer_complaints.loc[consumer_complaints['Product'].isin(cats), keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# keep very small portion for LM validation\n",
    "traindata, valdata = train_test_split(traindata, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_text = traindata['Consumer complaint narrative'].tolist()\n",
    "trn_labels = traindata['Product'].tolist()\n",
    "\n",
    "val_texts = valdata['Consumer complaint narrative'].tolist()\n",
    "val_labels = valdata['Product'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in spacy\n",
    "\n",
    "# load up spacy\n",
    "nlp = spacy.load('en_core_web_lg', disable=['ner', 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return [token.text for token in nlp.tokenizer(text)]\n",
    "\n",
    "trn_tokens = [tokenizer(text) for text in trn_text]\n",
    "val_tokens = [tokenizer(text) for text in val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# build vocab\n",
    "vocab = Counter(p for o in trn_tokens for p in o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vocab freq limits\n",
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in vocab.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reverse string to index\n",
    "import collections\n",
    "\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tokens to ids\n",
    "trn_lm = np.array([[stoi[o] for o in p] for p in trn_tokens])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in val_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation set\n",
    "df_trn, df_val = train_test_split(traindata, test_size = 0.4, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Complaint ID</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>795203</th>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>1435578</td>\n",
       "      <td>On XX/XX/2015, I made a mobile deposit of {$50...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Product  Complaint ID  \\\n",
       "795203  Bank account or service       1435578   \n",
       "\n",
       "                             Consumer complaint narrative  \n",
       "795203  On XX/XX/2015, I made a mobile deposit of {$50...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language model data\n",
    "data_lm = TextLMDataBunch.from_df(train_df=df_trn, valid_df=df_val, path = \"\")\n",
    "\n",
    "# Classifier model data\n",
    "data_class = TextClasDataBunch.from_df(path=\"\", train_df=df_trn, valid_df=df_val, \n",
    "                                       vocab=data_lm.train_ds.vocab, bs=32, \n",
    "                                      label_cols='Product', \n",
    "                                      text_cols='Consumer complaint narrative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TextClasDataBunch in module fastai.text.data:\n",
      "\n",
      "class TextClasDataBunch(TextDataBunch)\n",
      " |  Create a `TextDataBunch` suitable for training an RNN classifier.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TextClasDataBunch\n",
      " |      TextDataBunch\n",
      " |      fastai.basic_data.DataBunch\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  create(train_ds, valid_ds, test_ds=None, path:Union[pathlib.Path, str]='.', bs=64, pad_idx=1, pad_first=True, no_check:bool=False, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Function that transform the `datasets` in a `DataBunch` for classification.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from TextDataBunch:\n",
      " |  \n",
      " |  save(self, cache_name:Union[pathlib.Path, str]='tmp')\n",
      " |      Save the `DataBunch` in `self.path/cache_name` folder.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from TextDataBunch:\n",
      " |  \n",
      " |  from_csv(path:Union[pathlib.Path, str], csv_name, valid_pct:float=0.2, test:Union[str, NoneType]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, classes:Collection[str]=None, header='infer', text_cols:Union[int, Collection[int], str, Collection[str]]=1, label_cols:Union[int, Collection[int], str, Collection[str]]=0, label_delim:str=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from texts in csv files.\n",
      " |  \n",
      " |  from_df(path:Union[pathlib.Path, str], train_df:pandas.core.frame.DataFrame, valid_df:pandas.core.frame.DataFrame, test_df:Union[pandas.core.frame.DataFrame, NoneType]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, classes:Collection[str]=None, text_cols:Union[int, Collection[int], str, Collection[str]]=1, label_cols:Union[int, Collection[int], str, Collection[str]]=0, label_delim:str=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from DataFrames.\n",
      " |  \n",
      " |  from_folder(path:Union[pathlib.Path, str], train:str='train', valid:str='valid', test:Union[str, NoneType]=None, classes:Collection[Any]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, **kwargs) from builtins.type\n",
      " |      Create a `TextDataBunch` from text files in folders.\n",
      " |  \n",
      " |  from_ids(path:Union[pathlib.Path, str], vocab:fastai.text.transform.Vocab, train_ids:Collection[Collection[int]], valid_ids:Collection[Collection[int]], test_ids:Collection[Collection[int]]=None, train_lbls:Collection[Union[int, float]]=None, valid_lbls:Collection[Union[int, float]]=None, classes:Collection[Any]=None, processor:fastai.data_block.PreProcessor=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from ids, labels and a `vocab`.\n",
      " |  \n",
      " |  from_tokens(path:Union[pathlib.Path, str], trn_tok:Collection[Collection[str]], trn_lbls:Collection[Union[int, float]], val_tok:Collection[Collection[str]], val_lbls:Collection[Union[int, float]], vocab:fastai.text.transform.Vocab=None, tst_tok:Collection[Collection[str]]=None, classes:Collection[Any]=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from tokens and labels.\n",
      " |  \n",
      " |  load(path:Union[pathlib.Path, str], cache_name:Union[pathlib.Path, str]='tmp', processor:fastai.data_block.PreProcessor=None, **kwargs) from builtins.type\n",
      " |      Load a `TextDataBunch` from `path/cache_name`. `kwargs` are passed to the dataloader creation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  __getattr__(self, k:int) -> Any\n",
      " |  \n",
      " |  __init__(self, train_dl:torch.utils.data.dataloader.DataLoader, valid_dl:torch.utils.data.dataloader.DataLoader, fix_dl:torch.utils.data.dataloader.DataLoader=None, test_dl:Union[torch.utils.data.dataloader.DataLoader, NoneType]=None, device:torch.device=None, dl_tfms:Union[Collection[Callable], NoneType]=None, path:Union[pathlib.Path, str]='.', collate_fn:Callable=<function data_collate at 0x7fab66901400>, no_check:bool=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  add_tfm(self, tfm:Callable) -> None\n",
      " |  \n",
      " |  dl(self, ds_type:fastai.basic_data.DatasetType=<DatasetType.Valid: 2>) -> fastai.basic_data.DeviceDataLoader\n",
      " |      Returns appropriate `Dataset` for validation, training, or test (`ds_type`).\n",
      " |  \n",
      " |  export(self, fname:str='export.pkl')\n",
      " |      Export the minimal state of `self` for inference in `self.path/fname`.\n",
      " |  \n",
      " |  one_batch(self, ds_type:fastai.basic_data.DatasetType=<DatasetType.Train: 1>, detach:bool=True, denorm:bool=True, cpu:bool=True) -> Collection[torch.Tensor]\n",
      " |      Get one batch from the data loader of `ds_type`. Optionally `detach` and `denorm`.\n",
      " |  \n",
      " |  one_item(self, item, detach:bool=False, denorm:bool=False, cpu:bool=False)\n",
      " |      Get `item` into a batch. Optionally `detach` and `denorm`.\n",
      " |  \n",
      " |  sanity_check(self)\n",
      " |      Check the underlying data in the training set can be properly loaded.\n",
      " |  \n",
      " |  show_batch(self, rows:int=5, ds_type:fastai.basic_data.DatasetType=<DatasetType.Train: 1>, **kwargs) -> None\n",
      " |      Show a batch of data in `ds_type` on a few `rows`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  load_empty = _databunch_load_empty(path, fname:str='export.pkl') from builtins.type\n",
      " |      Load an empty `DataBunch` from the exported file in `path/fname` with optional `tfms`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  batch_size\n",
      " |  \n",
      " |  dls\n",
      " |  \n",
      " |  empty_val\n",
      " |  \n",
      " |  loss_func\n",
      " |  \n",
      " |  single_ds\n",
      " |  \n",
      " |  test_ds\n",
      " |  \n",
      " |  train_ds\n",
      " |  \n",
      " |  valid_ds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TextClasDataBunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# specify device type\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# we want the model to move to our GPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune pre trained model\n",
    "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model = learn.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:25 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>4.362731</th>\n",
       "    <th>2.892414</th>\n",
       "    <th>0.400162</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>3.886526</th>\n",
       "    <th>1.547345</th>\n",
       "    <th>0.404343</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>3.114805</th>\n",
       "    <th>1.655118</th>\n",
       "    <th>0.512033</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>2.369766</th>\n",
       "    <th>0.625688</th>\n",
       "    <th>0.540158</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>1.775460</th>\n",
       "    <th>0.166468</th>\n",
       "    <th>0.991254</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>1.351418</th>\n",
       "    <th>0.075207</th>\n",
       "    <th>0.993162</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>1.038464</th>\n",
       "    <th>0.054112</th>\n",
       "    <th>0.993506</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.824384</th>\n",
       "    <th>0.045929</th>\n",
       "    <th>0.994237</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.706353</th>\n",
       "    <th>0.046701</th>\n",
       "    <th>0.994115</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.583548</th>\n",
       "    <th>0.045468</th>\n",
       "    <th>0.994257</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the learner object with learning rate = 1e-2\n",
    "learn.fit_one_cycle(10, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://software.intel.com/en-us/articles/transfer-learning-in-natural-language-processing\n",
    "# save our encoder\n",
    "learn.save_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function text_classifier_learner in module fastai.text.learner:\n",
      "\n",
      "text_classifier_learner(data:fastai.basic_data.DataBunch, bptt:int=70, emb_sz:int=400, nh:int=1150, nl:int=3, pad_token:int=1, drop_mult:float=1.0, qrnn:bool=False, max_len:int=1400, lin_ftrs:Collection[int]=None, ps:Collection[float]=None, pretrained_model:str=None, **kwargs) -> 'TextClassifierLearner'\n",
      "    Create a RNN classifier from `data`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(text_classifier_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier\n",
    "learn_class = text_classifier_learner(data_class, drop_mult=0.7,\n",
    "                                     bptt=70)\n",
    "learn_class.load_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to GPU\n",
    "learn_class.model = learn_class.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [8/10 1:06:50<16:42]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.198741</th>\n",
       "    <th>1.250138</th>\n",
       "    <th>0.352343</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.191631</th>\n",
       "    <th>6.856156</th>\n",
       "    <th>0.334692</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>1.175679</th>\n",
       "    <th>44.809757</th>\n",
       "    <th>0.339127</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>1.193155</th>\n",
       "    <th>1.498763</th>\n",
       "    <th>0.349028</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>1.186574</th>\n",
       "    <th>5.420327</th>\n",
       "    <th>0.273363</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>1.180240</th>\n",
       "    <th>1.195099</th>\n",
       "    <th>0.372234</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>1.180224</th>\n",
       "    <th>1.193797</th>\n",
       "    <th>0.368336</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>1.178905</th>\n",
       "    <th>1.182137</th>\n",
       "    <th>0.368426</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='759' class='' max='2092', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      36.28% [759/2092 02:06<03:42 1.1764]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_class.fit_one_cycle(10, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "preds, targets = learn_class.get_preds()\n",
    "\n",
    "predictions = np.argmax(preds, axis = 1)\n",
    "pd.crosstab(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
