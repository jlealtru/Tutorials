{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/datawrestler/.fastai/data/imdb_sample/texts.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextDataBunch.from_csv(path, 'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TextDataBunch in module fastai.text.data:\n",
      "\n",
      "class TextDataBunch(fastai.basic_data.DataBunch)\n",
      " |  General class to get a `DataBunch` for NLP. Subclassed by `TextLMDataBunch` and `TextClasDataBunch`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TextDataBunch\n",
      " |      fastai.basic_data.DataBunch\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  save(self, cache_name:Union[pathlib.Path, str]='tmp')\n",
      " |      Save the `DataBunch` in `self.path/cache_name` folder.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_csv(path:Union[pathlib.Path, str], csv_name, valid_pct:float=0.2, test:Union[str, NoneType]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, classes:Collection[str]=None, header='infer', text_cols:Union[int, Collection[int], str, Collection[str]]=1, label_cols:Union[int, Collection[int], str, Collection[str]]=0, label_delim:str=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from texts in csv files.\n",
      " |  \n",
      " |  from_df(path:Union[pathlib.Path, str], train_df:pandas.core.frame.DataFrame, valid_df:pandas.core.frame.DataFrame, test_df:Union[pandas.core.frame.DataFrame, NoneType]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, classes:Collection[str]=None, text_cols:Union[int, Collection[int], str, Collection[str]]=1, label_cols:Union[int, Collection[int], str, Collection[str]]=0, label_delim:str=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from DataFrames.\n",
      " |  \n",
      " |  from_folder(path:Union[pathlib.Path, str], train:str='train', valid:str='valid', test:Union[str, NoneType]=None, classes:Collection[Any]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, **kwargs) from builtins.type\n",
      " |      Create a `TextDataBunch` from text files in folders.\n",
      " |  \n",
      " |  from_ids(path:Union[pathlib.Path, str], vocab:fastai.text.transform.Vocab, train_ids:Collection[Collection[int]], valid_ids:Collection[Collection[int]], test_ids:Collection[Collection[int]]=None, train_lbls:Collection[Union[int, float]]=None, valid_lbls:Collection[Union[int, float]]=None, classes:Collection[Any]=None, processor:fastai.data_block.PreProcessor=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from ids, labels and a `vocab`.\n",
      " |  \n",
      " |  from_tokens(path:Union[pathlib.Path, str], trn_tok:Collection[Collection[str]], trn_lbls:Collection[Union[int, float]], val_tok:Collection[Collection[str]], val_lbls:Collection[Union[int, float]], vocab:fastai.text.transform.Vocab=None, tst_tok:Collection[Collection[str]]=None, classes:Collection[Any]=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from tokens and labels.\n",
      " |  \n",
      " |  load(path:Union[pathlib.Path, str], cache_name:Union[pathlib.Path, str]='tmp', processor:fastai.data_block.PreProcessor=None, **kwargs) from builtins.type\n",
      " |      Load a `TextDataBunch` from `path/cache_name`. `kwargs` are passed to the dataloader creation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  __getattr__(self, k:int) -> Any\n",
      " |  \n",
      " |  __init__(self, train_dl:torch.utils.data.dataloader.DataLoader, valid_dl:torch.utils.data.dataloader.DataLoader, fix_dl:torch.utils.data.dataloader.DataLoader=None, test_dl:Union[torch.utils.data.dataloader.DataLoader, NoneType]=None, device:torch.device=None, dl_tfms:Union[Collection[Callable], NoneType]=None, path:Union[pathlib.Path, str]='.', collate_fn:Callable=<function data_collate at 0x7f2677b48bf8>, no_check:bool=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  add_tfm(self, tfm:Callable) -> None\n",
      " |  \n",
      " |  dl(self, ds_type:fastai.basic_data.DatasetType=<DatasetType.Valid: 2>) -> fastai.basic_data.DeviceDataLoader\n",
      " |      Returns appropriate `Dataset` for validation, training, or test (`ds_type`).\n",
      " |  \n",
      " |  export(self, fname:str='export.pkl')\n",
      " |      Export the minimal state of `self` for inference in `self.path/fname`.\n",
      " |  \n",
      " |  one_batch(self, ds_type:fastai.basic_data.DatasetType=<DatasetType.Train: 1>, detach:bool=True, denorm:bool=True, cpu:bool=True) -> Collection[torch.Tensor]\n",
      " |      Get one batch from the data loader of `ds_type`. Optionally `detach` and `denorm`.\n",
      " |  \n",
      " |  one_item(self, item, detach:bool=False, denorm:bool=False, cpu:bool=False)\n",
      " |      Get `item` into a batch. Optionally `detach` and `denorm`.\n",
      " |  \n",
      " |  sanity_check(self)\n",
      " |      Check the underlying data in the training set can be properly loaded.\n",
      " |  \n",
      " |  show_batch(self, rows:int=5, ds_type:fastai.basic_data.DatasetType=<DatasetType.Train: 1>, **kwargs) -> None\n",
      " |      Show a batch of data in `ds_type` on a few `rows`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  create(train_ds:torch.utils.data.dataset.Dataset, valid_ds:torch.utils.data.dataset.Dataset, test_ds:Union[torch.utils.data.dataset.Dataset, NoneType]=None, path:Union[pathlib.Path, str]='.', bs:int=64, num_workers:int=16, dl_tfms:Union[Collection[Callable], NoneType]=None, device:torch.device=None, collate_fn:Callable=<function data_collate at 0x7f2677b48bf8>, no_check:bool=False) -> 'DataBunch' from builtins.type\n",
      " |      Create a `DataBunch` from `train_ds`, `valid_ds` and maybe `test_ds` with a batch size of `bs`.\n",
      " |  \n",
      " |  load_empty = _databunch_load_empty(path, fname:str='export.pkl') from builtins.type\n",
      " |      Load an empty `DataBunch` from the exported file in `path/fname` with optional `tfms`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  batch_size\n",
      " |  \n",
      " |  dls\n",
      " |  \n",
      " |  empty_val\n",
      " |  \n",
      " |  loss_func\n",
      " |  \n",
      " |  single_ds\n",
      " |  \n",
      " |  test_ds\n",
      " |  \n",
      " |  train_ds\n",
      " |  \n",
      " |  valid_ds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TextDataBunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='90%'>  <col width='10%'>  <tr>\n",
       "    <th>text</th>\n",
       "    <th>target</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxup the xxup shop xxup around xxup the xxup corner is one of the xxunk and most feel - good romantic comedies ever made . xxmaj there 's just no getting around that , and it 's hard to actually put one 's feeling for this film into words . xxmaj it 's not one of those films that tries too hard , nor does it come up with</th>\n",
       "    <th>positive</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj xxunk , after xxunk ) , i can xxunk join both xxunk of \" xxmaj at xxmaj the xxmaj movies \" in taking xxmaj steven xxmaj soderbergh to task . \\n\\n xxmaj it 's usually satisfying to watch a film director change his style / subject ,</th>\n",
       "    <th>negative</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos i really wanted to love this show . i truly , honestly did . \\n\\n xxmaj for the first time , gay viewers get their own version of the \" xxmaj the xxmaj xxunk \" . xxmaj with the help of his obligatory \" hag \" xxmaj xxunk , xxmaj james , a good looking , well - to - do thirty - something has the chance of love</th>\n",
       "    <th>negative</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \\n\\n i 'm sure things did n't exactly go the same way in the real life of xxmaj homer xxmaj hickam as they did in the film adaptation of his book , xxmaj rocket xxmaj boys , but the movie \" xxmaj october xxmaj sky \" ( an xxunk of the book 's title ) is good enough to stand alone . i have not read xxmaj hickam 's</th>\n",
       "    <th>positive</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj to review this movie , i without any doubt would have to quote that memorable scene in xxmaj tarantino 's \" xxmaj pulp xxmaj fiction \" ( xxunk ) when xxmaj jules and xxmaj vincent are talking about xxmaj mia xxmaj wallace and what she does for a living . xxmaj jules tells xxmaj vincent that the \" xxmaj only thing she did worthwhile was pilot \" .</th>\n",
       "    <th>negative</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenization\n",
    "data = TextClasDataBunch.load(path)\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'the',\n",
       " ',']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numericalization\n",
    "data.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj this was an excellent xxunk episode , although i had never been seen the older ones , i never thought the doctor would go up against anything that is xxunk , extra xxunk of course but not xxunk . \n",
       "\n",
       " xxmaj this episode brings the things that we most fear and how would we humans , in a futuristic time , would fight and defeat real live evil when most odds say that would be impossible . \n",
       "\n",
       " xxmaj being that it 's a family film i am surprised that they brought some stuff in like fear and faith , especially if its also going to entertain xxmaj american audiences . xxmaj but who care about what xxmaj xxunk say , we rock ! xxmaj doctor xxmaj who has shown potential ever since from episode one from the new series in 2005 , first being so harmless to scary , from fun to serious , from light to darkness . i hope many old fans will one day soon say \" xxmaj the old xxmaj doctor xxmaj who has returned \" . \n",
       "\n",
       " 10 out of 10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens\n",
    "data.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   4,  20,  25,  48, 483,   0, 387,   9, 280])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numbers\n",
    "data.train_ds[0][0].data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TextList in module fastai.text.data:\n",
      "\n",
      "class TextList(fastai.data_block.ItemList)\n",
      " |  Basic `ItemList` for text data.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TextList\n",
      " |      fastai.data_block.ItemList\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, items:Iterator, vocab:fastai.text.transform.Vocab=None, pad_idx:int=1, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get(self, i)\n",
      " |      Subclass if you want to customize how to create item `i` from `self.items`.\n",
      " |  \n",
      " |  label_for_lm(self, **kwargs)\n",
      " |      A special labelling method for language models.\n",
      " |  \n",
      " |  reconstruct(self, t:torch.Tensor)\n",
      " |      Reconstuct one of the underlying item for its data `t`.\n",
      " |  \n",
      " |  show_xys(self, xs, ys, max_len:int=70) -> None\n",
      " |      Show the `xs` (inputs) and `ys` (targets). `max_len` is the maximum number of tokens displayed.\n",
      " |  \n",
      " |  show_xyzs(self, xs, ys, zs, max_len:int=70)\n",
      " |      Show `xs` (inputs), `ys` (targets) and `zs` (predictions). `max_len` is the maximum number of tokens displayed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_folder(path:Union[pathlib.Path, str]='.', extensions:Collection[str]={'.txt'}, vocab:fastai.text.transform.Vocab=None, processor:fastai.data_block.PreProcessor=None, **kwargs) -> 'TextList' from builtins.type\n",
      " |      Get the list of files in `path` that have a text suffix. `recurse` determines if we search subfolders.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from fastai.data_block.ItemList:\n",
      " |  \n",
      " |  __getitem__(self, idxs:int) -> Any\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |  \n",
      " |  __post_init__(self)\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  analyze_pred(self, pred:torch.Tensor)\n",
      " |      Called on `pred` before `reconstruct` for additional preprocessing.\n",
      " |  \n",
      " |  filter_by_folder(self, include=None, exclude=None)\n",
      " |      Only keep filenames in `include` folder or reject the ones in `exclude`.\n",
      " |  \n",
      " |  filter_by_func(self, func:Callable) -> 'ItemList'\n",
      " |      Only keep elements for which `func` returns `True`.\n",
      " |  \n",
      " |  filter_by_rand(self, p:float, seed:int=None)\n",
      " |      Keep random sample of `items` with probability `p` and an optional `seed`.\n",
      " |  \n",
      " |  get_label_cls(self, labels, label_cls:Callable=None, label_delim:str=None, **kwargs)\n",
      " |      Return `label_cls` or guess one from the first element of `labels`.\n",
      " |  \n",
      " |  label_const(self, const:Any=0, **kwargs) -> 'LabelList'\n",
      " |      Label every item with `const`.\n",
      " |  \n",
      " |  label_empty(self)\n",
      " |      Label every item with an `EmptyLabel`.\n",
      " |  \n",
      " |  label_from_df(self, cols:Union[int, Collection[int], str, Collection[str]]=1, **kwargs)\n",
      " |      Label `self.items` from the values in `cols` in `self.xtra`.\n",
      " |  \n",
      " |  label_from_folder(self, **kwargs) -> 'LabelList'\n",
      " |      Give a label to each filename depending on its folder.\n",
      " |  \n",
      " |  label_from_func(self, func:Callable, **kwargs) -> 'LabelList'\n",
      " |      Apply `func` to every input to get its label.\n",
      " |  \n",
      " |  label_from_list(self, labels:Iterator, **kwargs) -> 'LabelList'\n",
      " |      Label `self.items` with `labels`.\n",
      " |  \n",
      " |  label_from_re(self, pat:str, full_path:bool=False, **kwargs) -> 'LabelList'\n",
      " |      Apply the re in `pat` to determine the label of every filename.  If `full_path`, search in the full name.\n",
      " |  \n",
      " |  new(self, items:Iterator, processor:fastai.data_block.PreProcessor=None, **kwargs) -> 'ItemList'\n",
      " |      Create a new `ItemList` from `items`, keeping the same attributes.\n",
      " |  \n",
      " |  no_split(self)\n",
      " |      Don't split the data and create an empty validation set.\n",
      " |  \n",
      " |  process(self, processor=None)\n",
      " |      Apply `processor` or `self.processor` to `self`.\n",
      " |  \n",
      " |  process_one(self, item, processor=None)\n",
      " |      Apply `processor` or `self.processor` to `item`.\n",
      " |  \n",
      " |  random_split_by_pct(self, valid_pct:float=0.2, seed:int=None) -> 'ItemLists'\n",
      " |      Split the items randomly by putting `valid_pct` in the validation set, optional `seed` can be passed.\n",
      " |  \n",
      " |  split_by_files(self, valid_names:'ItemList') -> 'ItemLists'\n",
      " |      Split the data by using the names in `valid_names` for validation.\n",
      " |  \n",
      " |  split_by_fname_file(self, fname:Union[pathlib.Path, str], path:Union[pathlib.Path, str]=None) -> 'ItemLists'\n",
      " |      Split the data by using the names in `fname` for the validation set. `path` will override `self.path`.\n",
      " |  \n",
      " |  split_by_folder(self, train:str='train', valid:str='valid') -> 'ItemLists'\n",
      " |      Split the data depending on the folder (`train` or `valid`) in which the filenames are.\n",
      " |  \n",
      " |  split_by_idx(self, valid_idx:Collection[int]) -> 'ItemLists'\n",
      " |      Split the data according to the indexes in `valid_idx`.\n",
      " |  \n",
      " |  split_by_idxs(self, train_idx, valid_idx)\n",
      " |      Split the data between `train_idx` and `valid_idx`.\n",
      " |  \n",
      " |  split_by_list(self, train, valid)\n",
      " |      Split the data between `train` and `valid`.\n",
      " |  \n",
      " |  split_by_valid_func(self, func:Callable) -> 'ItemLists'\n",
      " |      Split the data by result of `func` (which returns `True` for validation set).\n",
      " |  \n",
      " |  split_from_df(self, col:Union[int, Collection[int], str, Collection[str]]=2)\n",
      " |      Split the data from the `col` in the dataframe in `self.xtra`.\n",
      " |  \n",
      " |  to_text(self, fn:str)\n",
      " |      Save `self.items` to `fn` in `self.path`.\n",
      " |  \n",
      " |  use_partial_data(self, sample_pct:float=1.0, seed:int=None) -> 'ItemList'\n",
      " |      Use only a sample of `sample_pct`of the full dataset and an optional `seed`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from fastai.data_block.ItemList:\n",
      " |  \n",
      " |  from_csv(path:Union[pathlib.Path, str], csv_name:str, cols:Union[int, Collection[int], str, Collection[str]]=0, header:str='infer', **kwargs) -> 'ItemList' from builtins.type\n",
      " |      Create an `ItemList` in `path` from the inputs in the `cols` of `path/csv_name` opened with `header`.\n",
      " |  \n",
      " |  from_df(df:pandas.core.frame.DataFrame, path:Union[pathlib.Path, str]='.', cols:Union[int, Collection[int], str, Collection[str]]=0, **kwargs) -> 'ItemList' from builtins.type\n",
      " |      Create an `ItemList` in `path` from the inputs in the `cols` of `df`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from fastai.data_block.ItemList:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TextList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9238603655c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use the datablock api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m data = (TextList.from_csv(path, 'texts.csv', col='text')\n\u001b[0m\u001b[1;32m      3\u001b[0m        \u001b[0;34m.\u001b[0m\u001b[0msplit_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0;34m.\u001b[0m\u001b[0mlabel_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        .databunch())\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/fastai/data_block.py\u001b[0m in \u001b[0;36mfrom_csv\u001b[0;34m(cls, path, csv_name, cols, header, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;34m\"Create an `ItemList` in `path` from the inputs in the `cols` of `path/csv_name` opened with `header`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcsv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_relative_item_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/fastai/data_block.py\u001b[0m in \u001b[0;36mfrom_df\u001b[0;34m(cls, df, path, cols, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_names_to_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"You have NaN values in column(s) {cols} of your dataframe, please fix it.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_maybe_squeeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/fastai/text/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, items, vocab, pad_idx, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mVocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_new\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'vocab'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pad_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'col'"
     ]
    }
   ],
   "source": [
    "# use the datablock api\n",
    "data = (TextList.from_csv(path, 'texts.csv', col='text')\n",
    "       .split_from_df(cols=2)\n",
    "       .label_from_df(cols=0)\n",
    "       .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab full dataset\n",
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/datawrestler/.fastai/data/imdb/tmp_lm'),\n",
       " PosixPath('/home/datawrestler/.fastai/data/imdb/imdb.vocab'),\n",
       " PosixPath('/home/datawrestler/.fastai/data/imdb/test'),\n",
       " PosixPath('/home/datawrestler/.fastai/data/imdb/README'),\n",
       " PosixPath('/home/datawrestler/.fastai/data/imdb/train'),\n",
       " PosixPath('/home/datawrestler/.fastai/data/imdb/unsup'),\n",
       " PosixPath('/home/datawrestler/.fastai/data/imdb/tmp_clas')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/datawrestler/.fastai/data/imdb/train/unsupBow.feat'),\n",
       " PosixPath('/home/datawrestler/.fastai/data/imdb/train/neg'),\n",
       " PosixPath('/home/datawrestler/.fastai/data/imdb/train/labeledBow.feat'),\n",
       " PosixPath('/home/datawrestler/.fastai/data/imdb/train/pos')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_imdb = '/home/datawrestler/.fastai/data/imdb/train/'\n",
    "imdb_path = '/home/datawrestler/.fastai/data/imdb/train/pos/8851_7.txt'\n",
    "\n",
    "all_text = []\n",
    "all_labels = []\n",
    "\n",
    "for label in ['pos', 'neg']:\n",
    "    path = os.path.join(base_imdb, label)\n",
    "    files = os.listdir(path)\n",
    "    text_files = [file for file in files if file.endswith('.txt')]\n",
    "    for tfile in text_files:\n",
    "        text = open(os.path.join(path, tfile), 'r').read()\n",
    "        all_text.append(text)\n",
    "        all_labels.append(label)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17672</th>\n",
       "      <td>I absolutely hate this programme, what kind of...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>I think this is a lovely family movie. There a...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7881</th>\n",
       "      <td>I became a fan of the TV series `Homicide: Lif...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>The one of the most remarkable sci-fi movies o...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>Engrossing drama of four men on a canoing week...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text labels\n",
       "17672  I absolutely hate this programme, what kind of...    neg\n",
       "4748   I think this is a lovely family movie. There a...    pos\n",
       "7881   I became a fan of the TV series `Homicide: Lif...    pos\n",
       "3738   The one of the most remarkable sci-fi movies o...    pos\n",
       "7160   Engrossing drama of four men on a canoing week...    pos"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'text': all_text,\n",
    "                  'labels': all_labels})\n",
    "\n",
    "df = df.sample(n=df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TextLMDataBunch in module fastai.text.data:\n",
      "\n",
      "class TextLMDataBunch(TextDataBunch)\n",
      " |  Create a `TextDataBunch` suitable for training a language model.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TextLMDataBunch\n",
      " |      TextDataBunch\n",
      " |      fastai.basic_data.DataBunch\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  create(train_ds, valid_ds, test_ds=None, path:Union[pathlib.Path, str]='.', no_check:bool=False, bs=64, num_workers:int=0, device:torch.device=None, collate_fn:Callable=<function data_collate at 0x7f2677b48bf8>, dl_tfms:Union[Collection[Callable], NoneType]=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` in `path` from the `datasets` for language modelling.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from TextDataBunch:\n",
      " |  \n",
      " |  save(self, cache_name:Union[pathlib.Path, str]='tmp')\n",
      " |      Save the `DataBunch` in `self.path/cache_name` folder.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from TextDataBunch:\n",
      " |  \n",
      " |  from_csv(path:Union[pathlib.Path, str], csv_name, valid_pct:float=0.2, test:Union[str, NoneType]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, classes:Collection[str]=None, header='infer', text_cols:Union[int, Collection[int], str, Collection[str]]=1, label_cols:Union[int, Collection[int], str, Collection[str]]=0, label_delim:str=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from texts in csv files.\n",
      " |  \n",
      " |  from_df(path:Union[pathlib.Path, str], train_df:pandas.core.frame.DataFrame, valid_df:pandas.core.frame.DataFrame, test_df:Union[pandas.core.frame.DataFrame, NoneType]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, classes:Collection[str]=None, text_cols:Union[int, Collection[int], str, Collection[str]]=1, label_cols:Union[int, Collection[int], str, Collection[str]]=0, label_delim:str=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from DataFrames.\n",
      " |  \n",
      " |  from_folder(path:Union[pathlib.Path, str], train:str='train', valid:str='valid', test:Union[str, NoneType]=None, classes:Collection[Any]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, **kwargs) from builtins.type\n",
      " |      Create a `TextDataBunch` from text files in folders.\n",
      " |  \n",
      " |  from_ids(path:Union[pathlib.Path, str], vocab:fastai.text.transform.Vocab, train_ids:Collection[Collection[int]], valid_ids:Collection[Collection[int]], test_ids:Collection[Collection[int]]=None, train_lbls:Collection[Union[int, float]]=None, valid_lbls:Collection[Union[int, float]]=None, classes:Collection[Any]=None, processor:fastai.data_block.PreProcessor=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from ids, labels and a `vocab`.\n",
      " |  \n",
      " |  from_tokens(path:Union[pathlib.Path, str], trn_tok:Collection[Collection[str]], trn_lbls:Collection[Union[int, float]], val_tok:Collection[Collection[str]], val_lbls:Collection[Union[int, float]], vocab:fastai.text.transform.Vocab=None, tst_tok:Collection[Collection[str]]=None, classes:Collection[Any]=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from tokens and labels.\n",
      " |  \n",
      " |  load(path:Union[pathlib.Path, str], cache_name:Union[pathlib.Path, str]='tmp', processor:fastai.data_block.PreProcessor=None, **kwargs) from builtins.type\n",
      " |      Load a `TextDataBunch` from `path/cache_name`. `kwargs` are passed to the dataloader creation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  __getattr__(self, k:int) -> Any\n",
      " |  \n",
      " |  __init__(self, train_dl:torch.utils.data.dataloader.DataLoader, valid_dl:torch.utils.data.dataloader.DataLoader, fix_dl:torch.utils.data.dataloader.DataLoader=None, test_dl:Union[torch.utils.data.dataloader.DataLoader, NoneType]=None, device:torch.device=None, dl_tfms:Union[Collection[Callable], NoneType]=None, path:Union[pathlib.Path, str]='.', collate_fn:Callable=<function data_collate at 0x7f2677b48bf8>, no_check:bool=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  add_tfm(self, tfm:Callable) -> None\n",
      " |  \n",
      " |  dl(self, ds_type:fastai.basic_data.DatasetType=<DatasetType.Valid: 2>) -> fastai.basic_data.DeviceDataLoader\n",
      " |      Returns appropriate `Dataset` for validation, training, or test (`ds_type`).\n",
      " |  \n",
      " |  export(self, fname:str='export.pkl')\n",
      " |      Export the minimal state of `self` for inference in `self.path/fname`.\n",
      " |  \n",
      " |  one_batch(self, ds_type:fastai.basic_data.DatasetType=<DatasetType.Train: 1>, detach:bool=True, denorm:bool=True, cpu:bool=True) -> Collection[torch.Tensor]\n",
      " |      Get one batch from the data loader of `ds_type`. Optionally `detach` and `denorm`.\n",
      " |  \n",
      " |  one_item(self, item, detach:bool=False, denorm:bool=False, cpu:bool=False)\n",
      " |      Get `item` into a batch. Optionally `detach` and `denorm`.\n",
      " |  \n",
      " |  sanity_check(self)\n",
      " |      Check the underlying data in the training set can be properly loaded.\n",
      " |  \n",
      " |  show_batch(self, rows:int=5, ds_type:fastai.basic_data.DatasetType=<DatasetType.Train: 1>, **kwargs) -> None\n",
      " |      Show a batch of data in `ds_type` on a few `rows`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  load_empty = _databunch_load_empty(path, fname:str='export.pkl') from builtins.type\n",
      " |      Load an empty `DataBunch` from the exported file in `path/fname` with optional `tfms`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  batch_size\n",
      " |  \n",
      " |  dls\n",
      " |  \n",
      " |  empty_val\n",
      " |  \n",
      " |  loss_func\n",
      " |  \n",
      " |  single_ds\n",
      " |  \n",
      " |  test_ds\n",
      " |  \n",
      " |  train_ds\n",
      " |  \n",
      " |  valid_ds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TextLMDataBunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return [token for token in nlp.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = (TextLMDataBunch.from_df(train_df=train, valid_df=val,\n",
    "                                  text_cols='text', path=base_imdb, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   4,  53,  18, 321,  45,   8, 372,  10, 693])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numbers\n",
    "data_lm.train_ds[0][0].data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='5%'>  <col width='95%'>  <tr>\n",
       "    <th>idx</th>\n",
       "    <th>text</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>even if i have n't seen all his films yet , i 'd have to say that this is xxmaj spielberg at his peak . xxmaj it 's pretty sad to see that movies as great as \" xxmaj the xxmaj color xxmaj purple \" do n't come along too often 'cause i think all of us are in desperate need of first - class motion picture entertainment in these</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>justin and xxmaj june xxmaj duprez were great in the leading roles of lovers , both of them slightly and refreshingly stilted , but the parts did n't call for a huge range of emotions : only pure love mattered . \\n\\n xxmaj there 's a couple of mildly violent images in it , but rest assured this is a glorious feelgood experience with a 100 % positive message ,</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>names , but i ca n't remember what they are for the likes of me . xxmaj he fights off this invading male , to win her love . xxmaj they later on create a den , and the vixen gives birth to four adorable xxunk of which is blind . xxmaj there are many happy and playful moments featuring the fox family , but tragedy and bad luck strike</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>enough atmosphere to shake a stick at , xxmaj undying is the game to beat in my books as the best horror title . i just wish that this had made it to a console system but alas poor xxup pc sales xxunk that one in the bud . xxbos i 've seen a slew of \" 80s rocker horrors \" over the years , from rubbish like \" xxmaj</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>, great acting and a superb atmosphere . \\n\\n xxmaj in the film you will follow 8 people for one day in the city of antwerp , they are all individuals and sometimes plain weird ( that 's how i love them ! ) . \\n\\n i 'm not going to say anything else , just go see and enjoy it . xxbos xxmaj it 's pretty bad when the</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# specify device type\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function language_model_learner in module fastai.text.learner:\n",
      "\n",
      "language_model_learner(data:fastai.basic_data.DataBunch, bptt:int=70, emb_sz:int=400, nh:int=1150, nl:int=3, pad_token:int=1, drop_mult:float=1.0, tie_weights:bool=True, bias:bool=True, qrnn:bool=False, pretrained_model:str=None, pretrained_fnames:Union[Tuple[str, str], NoneType]=None, **kwargs) -> 'LanguageLearner'\n",
      "    Create a `Learner` with a language model from `data`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(language_model_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_mult = dropout rate\n",
    "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model = learn.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 04:18 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>4.349803</th>\n",
       "    <th>4.193694</th>\n",
       "    <th>0.273369</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fine tune last layers\n",
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='72' class='' max='1516', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      4.75% [72/1516 00:13<04:20 5.9014]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit one cycle only calibrates the last layers. To unfreeze the middle weights,\n",
    "# we can unfreeze the weights and retrain\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "learn.save('fine_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load up a model\n",
    "# learn.load('fine_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generate text\n",
    "learn.predict('I like this movie because ', 100, temperature=1.1, min_p=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to save the model but also its encoer, the parts that is responsible \n",
    "# for creating and updating the hidden state. For the next part, we don't\n",
    "# care about the part that tries to guess the next word\n",
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TextClasDataBunch in module fastai.text.data:\n",
      "\n",
      "class TextClasDataBunch(TextDataBunch)\n",
      " |  Create a `TextDataBunch` suitable for training an RNN classifier.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TextClasDataBunch\n",
      " |      TextDataBunch\n",
      " |      fastai.basic_data.DataBunch\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  create(train_ds, valid_ds, test_ds=None, path:Union[pathlib.Path, str]='.', bs=64, pad_idx=1, pad_first=True, no_check:bool=False, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Function that transform the `datasets` in a `DataBunch` for classification.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from TextDataBunch:\n",
      " |  \n",
      " |  save(self, cache_name:Union[pathlib.Path, str]='tmp')\n",
      " |      Save the `DataBunch` in `self.path/cache_name` folder.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from TextDataBunch:\n",
      " |  \n",
      " |  from_csv(path:Union[pathlib.Path, str], csv_name, valid_pct:float=0.2, test:Union[str, NoneType]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, classes:Collection[str]=None, header='infer', text_cols:Union[int, Collection[int], str, Collection[str]]=1, label_cols:Union[int, Collection[int], str, Collection[str]]=0, label_delim:str=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from texts in csv files.\n",
      " |  \n",
      " |  from_df(path:Union[pathlib.Path, str], train_df:pandas.core.frame.DataFrame, valid_df:pandas.core.frame.DataFrame, test_df:Union[pandas.core.frame.DataFrame, NoneType]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, classes:Collection[str]=None, text_cols:Union[int, Collection[int], str, Collection[str]]=1, label_cols:Union[int, Collection[int], str, Collection[str]]=0, label_delim:str=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from DataFrames.\n",
      " |  \n",
      " |  from_folder(path:Union[pathlib.Path, str], train:str='train', valid:str='valid', test:Union[str, NoneType]=None, classes:Collection[Any]=None, tokenizer:fastai.text.transform.Tokenizer=None, vocab:fastai.text.transform.Vocab=None, **kwargs) from builtins.type\n",
      " |      Create a `TextDataBunch` from text files in folders.\n",
      " |  \n",
      " |  from_ids(path:Union[pathlib.Path, str], vocab:fastai.text.transform.Vocab, train_ids:Collection[Collection[int]], valid_ids:Collection[Collection[int]], test_ids:Collection[Collection[int]]=None, train_lbls:Collection[Union[int, float]]=None, valid_lbls:Collection[Union[int, float]]=None, classes:Collection[Any]=None, processor:fastai.data_block.PreProcessor=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from ids, labels and a `vocab`.\n",
      " |  \n",
      " |  from_tokens(path:Union[pathlib.Path, str], trn_tok:Collection[Collection[str]], trn_lbls:Collection[Union[int, float]], val_tok:Collection[Collection[str]], val_lbls:Collection[Union[int, float]], vocab:fastai.text.transform.Vocab=None, tst_tok:Collection[Collection[str]]=None, classes:Collection[Any]=None, **kwargs) -> fastai.basic_data.DataBunch from builtins.type\n",
      " |      Create a `TextDataBunch` from tokens and labels.\n",
      " |  \n",
      " |  load(path:Union[pathlib.Path, str], cache_name:Union[pathlib.Path, str]='tmp', processor:fastai.data_block.PreProcessor=None, **kwargs) from builtins.type\n",
      " |      Load a `TextDataBunch` from `path/cache_name`. `kwargs` are passed to the dataloader creation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  __getattr__(self, k:int) -> Any\n",
      " |  \n",
      " |  __init__(self, train_dl:torch.utils.data.dataloader.DataLoader, valid_dl:torch.utils.data.dataloader.DataLoader, fix_dl:torch.utils.data.dataloader.DataLoader=None, test_dl:Union[torch.utils.data.dataloader.DataLoader, NoneType]=None, device:torch.device=None, dl_tfms:Union[Collection[Callable], NoneType]=None, path:Union[pathlib.Path, str]='.', collate_fn:Callable=<function data_collate at 0x7f2677b48bf8>, no_check:bool=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  add_tfm(self, tfm:Callable) -> None\n",
      " |  \n",
      " |  dl(self, ds_type:fastai.basic_data.DatasetType=<DatasetType.Valid: 2>) -> fastai.basic_data.DeviceDataLoader\n",
      " |      Returns appropriate `Dataset` for validation, training, or test (`ds_type`).\n",
      " |  \n",
      " |  export(self, fname:str='export.pkl')\n",
      " |      Export the minimal state of `self` for inference in `self.path/fname`.\n",
      " |  \n",
      " |  one_batch(self, ds_type:fastai.basic_data.DatasetType=<DatasetType.Train: 1>, detach:bool=True, denorm:bool=True, cpu:bool=True) -> Collection[torch.Tensor]\n",
      " |      Get one batch from the data loader of `ds_type`. Optionally `detach` and `denorm`.\n",
      " |  \n",
      " |  one_item(self, item, detach:bool=False, denorm:bool=False, cpu:bool=False)\n",
      " |      Get `item` into a batch. Optionally `detach` and `denorm`.\n",
      " |  \n",
      " |  sanity_check(self)\n",
      " |      Check the underlying data in the training set can be properly loaded.\n",
      " |  \n",
      " |  show_batch(self, rows:int=5, ds_type:fastai.basic_data.DatasetType=<DatasetType.Train: 1>, **kwargs) -> None\n",
      " |      Show a batch of data in `ds_type` on a few `rows`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  load_empty = _databunch_load_empty(path, fname:str='export.pkl') from builtins.type\n",
      " |      Load an empty `DataBunch` from the exported file in `path/fname` with optional `tfms`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from fastai.basic_data.DataBunch:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  batch_size\n",
      " |  \n",
      " |  dls\n",
      " |  \n",
      " |  empty_val\n",
      " |  \n",
      " |  loss_func\n",
      " |  \n",
      " |  single_ds\n",
      " |  \n",
      " |  test_ds\n",
      " |  \n",
      " |  train_ds\n",
      " |  \n",
      " |  valid_ds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TextClasDataBunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "test, val = train_test_split(test, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = (TextClasDataBunch.from_df(train_df=train, valid_df=val, \n",
    "                                      test_df=test, vocab=data_lm.vocab, \n",
    "                                      path=base_imdb, label_cols='labels', \n",
    "                                      text_cols='text', bs=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create learner\n",
    "learn = text_classifier_learner(data_clas, drop_mult=0.5)\n",
    "learn.model = learn.model.to(device)\n",
    "learn.load_encoder('fine_tuned_enc')\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "# find the learning rate\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmcXGWd7/HPr6p6TXrfknSn09kgCUsSCCRgFARE4KoEZBwyOog4wyyKyzDe6+gd9eKCqHN94TIqOoDMOCCi+AIu+xp2aGiSkIXsS2ftdJZOL7U/94+qrnSaTtIhfWrp+r5fr3qlzjlP1fn1SXf96lnO85hzDhEREQBfpgMQEZHsoaQgIiIpSgoiIpKipCAiIilKCiIikqKkICIiKUoKIiKSoqQgIiIpSgoiIpIS8OqNzex24CPAbufcqUMcnwHcAZwBfN0596PhvG9tba1raWkZyVBFREa9N954Y49zru5Y5TxLCsCdwM+Au45wfC/wBWDR8bxpS0sLra2tJxaZiEieMbPNwynnWfORc24JiQ/+Ix3f7Zx7HYh4FYOIiByfnOhTMLPrzazVzFo7OjoyHY6IyKiVE0nBOXebc26ec25eXd0xm8REROQ9yomkICIi6aGkICIiKV4OSb0bOB+oNbN24JtAAYBz7pdmNg5oBcqBuJl9CZjlnOvyKiYRETk6z5KCc27xMY7vBJq8Or+IiBw/NR+JiOSAW59cy/NrvR99qaQgIpIDfvr0Wl5e3+n5eZQURESyXCQWJxp3FBf4PT+XkoKISJYLRmIAFBd4/5GtpCAikuWCkTiAagoiIjKgphBQUhARyXuhaDIpFCopiIjkvVTzUUB9CiIiee9QR7NqCiIieU8dzSIikqIhqSIiktKn5iMREemnIakiIpISjPb3Kaj5SEQk74Uiuk9BRESS1HwkIiIpwUgcn0GB3zw/l5KCiEiWC0ZiFBf4MVNSEBHJe8FoLC3DUUFJQUQk6/WF42mZ9wiUFEREsp5qCiIikhKKxChSUhAREUiMPipJw41roKQgIpL1+kcfpYOSgohIllOfgoiIpAQj8bTMewRKCiIiWS8YiaVligtQUhARyXrBSFyjj0REJCHR0azmIxERQaOPREQkKRqLE407SpQUREQknauugZKCiEhWSy2wo5qCiIikc9U1UFIQEclqwUii+ago15uPzOx2M9ttZm8f4biZ2U/MbJ2ZLTOzM7yKRUQkV42m5qM7gUuOcvxSYHrycT3wCw9jERHJSaMmKTjnlgB7j1LkcuAul/AKUGlm472KR0QkF/U3H+XDymuNwNYB2+3JfSIiktRfUygpzPGawkgys+vNrNXMWjs6OjIdjohI2gSjo6T5aBi2ARMHbDcl972Lc+4259w859y8urq6tAQnIpINDjUfjf6k8ABwTXIU0gLggHNuRwbjERHJOoc6mtPzcR3w6o3N7G7gfKDWzNqBbwIFAM65XwIPA5cB64Be4DNexSIikqv6k0K6ps72LCk45xYf47gDPufV+UVERoOQ5j4SEZF+feEYZlDoV1IQEcl7/UtxmllazqekICKSxYLRWNruUQAlBRGRrBaMxNN2NzMoKYiIZLV0LsUJSgoiIlktGImnbTgqKCmIiGS1UDSWtuGooKQgIpLV+kcfpYuSgohIFgtG4qopiIhIQp86mkVEpF8wEqNESUFERECjj0REZIBQRKOPREQkKRhVn4KIiACxuCMScxqSKiIi6V91DZQURESy1qGkoJqCiEje61NNQURE+gUj/UtxqqYgIpL31HwkIiIpoaiSgoiIJKWaj7TymoiIqPlIRERS1NEsIiIpunlNRERSgupoFhGRfn1hJQUREUkKRfv7FNR8JCKS94KRGGZQ6FdSEBHJe8FIjOKAHzNL2zmVFEREslQwEk9r0xEoKYiIZK1gJL2rroGSgohI1gpG40oKIiKSEIzEKErjvEegpCAikrVGXfORmV1iZu+Y2Toz++oQxyeZ2VNmtszMnjWzJi/jERHJJcFIjJLRkhTMzA/8HLgUmAUsNrNZg4r9CLjLOXc6cBNws1fxiIjkmtE2+uhsYJ1zboNzLgzcA1w+qMws4Onk82eGOC4ikrdGW/NRI7B1wHZ7ct9AS4Erk8+vAMrMrMbDmEREckYwOrqSwnD8M3CembUB5wHbgNjgQmZ2vZm1mllrR0dHumMUEcmI0dZ8tA2YOGC7KbkvxTm33Tl3pXNuLvD15L79g9/IOXebc26ec25eXV2dhyGLiGSPxJDU0VNTeB2YbmaTzawQuBp4YGABM6s1s/4Y/gW43cN4RERySigyim5ec85Fgc8DjwGrgHudcyvM7CYz+1iy2PnAO2a2BmgAvutVPCIiuSQWd4Rj6W8+Cnj55s65h4GHB+37xoDn9wH3eRmDiEgu6l+Kc9TcpyAiIu/dofWZlRRERPJeMAOrroGSgohIVsrqmoKZTTWzouTz883sC2ZW6W1oIiL5qz8pZOuQ1D8CMTObBtxG4v6D//YsKhGRPBeMZHfzUTw5xPQK4KfOua8A470LS0Qkv4WyufkIiJjZYuDTwEPJfQXehCQiIsFodieFzwDnAN91zm00s8nAf3oXlohIfusLJ5qP0n2fwrBuXnPOrQS+AGBmVUCZc+4WLwMTEclnh0YfZWGfQnJVtHIzqwbeBH5tZv/X29BERPJXtjcfVTjnukisfXCXc24+cJF3YYmI5LfU6KMsHZIaMLPxwCc41NEsIiIeSd2nkI3NRyTWT34MWO+ce93MpgBrvQtLRCS/hSIxzKAokIWzpDrn/gD8YcD2BuDjXgUlIpLvgtE4RQEfZpbW8w63o7nJzO43s93Jxx/NrMnr4ERE8lUwkv71mWH4zUd3kFg1bULy8WByn4iIeKAvHEv7PQow/KRQ55y7wzkXTT7uBLRYsoiIR4LR9C/FCcNPCp1m9ikz8ycfnwI6vQxMRCSfBSOxtHcyw/CTwnUkhqPuBHYAVwHXehSTiEjey+o+BefcZufcx5xzdc65eufcIjT6SETEM6FIPO1TXMCJrbz2TyMWhYiIpDjn2NTZw7jy4rSf+0SSQnoHz4qI5IkdB4LsPhhibnNV2s99IknBjVgUIiKS0rZlPwBzm9O/6vFR72g2s4MM/eFvQIknEYmI5Lm2LfsoCviYMa487ec+alJwzpWlKxAREUlo27qfUxsrKMziIakiIpIG4Wic5dsOMHdi+puOQElBRCSrrN7ZRTgaz0gnMygpiIhklUx2MoOSgohIVmnbso+G8iLGV6T/HgVQUhARySptW/czZ2Jl2tdR6KekICKSJTq7Q2zu7M1YfwIoKYiIZI2l7cn+hAyNPAIlBRGRrNG2ZT9+n3FaU0XGYlBSEBHJEm1b9jNjXBmlhUe9r9hTSgoiIlkgFne8lexkziQlBRGRLLC+o5vuUDSjnczgcVIws0vM7B0zW2dmXx3ieLOZPWNmbWa2zMwu8zIeEZFs9VaGb1rr51lSMDM/8HPgUmAWsNjMZg0q9r+Be51zc4GrgX/3Kh4RkWz28oZOKksLmFwzJqNxeFlTOBtY55zb4JwLA/cAlw8q44D+uWErgO0exiMikpWCkRhPrNzFxbMa8Pkyu36Zl0mhEdg6YLs9uW+gbwGfMrN24GHghqHeyMyuN7NWM2vt6OjwIlYRkYx59p0OukNRPnL6hEyHkvGO5sXAnc65JuAy4D/N7F0xOeduc87Nc87Nq6urS3uQIiJeemjZdqrHFHLu1JpMh+JpUtgGTByw3ZTcN9BngXsBnHMvA8VArYcxiYhkld5wlKdW7ebSU8cR8Gf6e7q3SeF1YLqZTTazQhIdyQ8MKrMFuBDAzGaSSApqHxKRvPHUqt30RWJ8dHbmm47Aw6TgnIsCnwceA1aRGGW0wsxuMrOPJYvdCPytmS0F7gaudc4NtSa0iMio9ODS7TSUF3FWS3WmQwGOsUbziXLOPUyiA3ngvm8MeL4SeJ+XMYiIZKuuYIRn3+ngkwua8Wd41FG/zDdgiYjkqSdW7CIci2dN0xEoKYiIZMyDy7bTWFmS0amyB1NSEBHJgH09YV5Yu4ePzB6fsVXWhqKkICKSAY+t2Ek07vhoFtywNpCSgohIBjy+chdNVSWcMqH82IXTSElBRCTNukNRXli3h4tnjcuqpiNQUhARSbslazoIR+N8+JSGTIfyLkoKIiJp9viKnVSPKeTMSZldUGcoSgoiImkUjsZ5avVuLpxRnxVzHQ2WfRGJiIxir27s5GAwysWnjMt0KENSUhARSaPHV+yipMDP+6dn54TQSgoiImkSjzueWLmLD5xUS3GBP9PhDElJQUQkTZZvO8DOriAXz8rOpiNQUhARSZvHV+7E7zMunFmf6VCOSElBRCRNHluxi/mTq6ksLcx0KEekpCAikgZb9/aybnc3H5qVfTesDaSkICKSBlv39QJw8riyDEdydEoKIiJp0NkdBqB2bFGGIzk6JQURkTTo7A4BUDMme/sTQElBRCQtOnvC+Iys7mQGJQURkbTo7AlTVVqI35ddU2UPpqQgIpIGnd0hasZmdy0BlBRERNKisztMzZjs7mQGJQURkbTY2xOmWjUFEREB2NMdojbLRx4BBDIdQLba0x2iOxilMOCjKOCjpNBPaaEul4gcv3A0TlcwSk2W36MASgqH2bSnh8dW7OTRFTtp27L/XcdbakpZMKWGBVNqmDm+nHW7u1nWvp+l7fvZ0tlLNO6IxR0x52isLOHjZzSxaG4j1Tnw7UBEvLO3J3HjWi50NCspkEgGX7t/OS+t7wTg1MZybvzQSTRVlxCKxAlF43SHorRt2c//W76De17fmnptgd+YOb6cBVNrKAr48Jnh9xlvbd3PTQ+t5OZHVnHRzAbOnlxNzdgiascWUj2mkEjUcTAY4WAoSk8oSjTuiCcTytiiAOdOraWubOhvFd2hKK9t7OTFdZ20bdnH2ZNr+OzCye8qH47G2dUVZHxFcVYu+yeSLzp7cuPGNcjzpBCLO+54cSM/evwdCnw+vnrpDD5y+niaqkqP+ppVO7pYs+sg0+rHcvK4MooCQy+WsXpnF39obefPbdt45O2dxx3f7KYKzj+5nqaqErbs7WVTZy8b93SzesdBonFHYcDHjHFl/GrJeu54cSNXnzWRxfObWbWjiydX7mbJmg4OhqIEfEZzTSlTascysbqEurIiascWUTe2iEk1pUyqGZP1Y6dFcln/FBe50HxkzrlMx3Bc5s2b51pbW4/7dbG4o7MnRMfBELsPhujoCnHP61t4c8t+LphRz/euOI1xFcUeRJxYbWl/X4TO7hAd3SH29oQpCvgZWxSgrDjAmKIAAV+ihuEzo+NgiGff2c0z7+ymbet+nAOfQVNVKZNqSjmtsYKF02o5Y1IVxQV+NnR088vn1vOnN7cRjSf+P+vKirhwRj2nNVXQvq+PDR3dbNzTQ/u+PnrDscPiKy30c/K4MmaOL2dceTHlxQEqSgsoKQhwoC9Mx8EQe7rD9IVjNFaV0FxdSnNNKXVjiyjw+/D7jAK/UVZcoOQiMoT729r58u+X8vSN5zGlbmxGYjCzN5xz845VLm9qCg8u3c6Xfv/WYfsqSwv48V/OZtGcRsy8+zDz+YzqMYlmo+kNx54hcVxFMac1VXDDhdPZ1xNmf1+ExsoSCgNDNwFNqRvLD66azRcvOomnV+3i9KZKTmuswHeED+jecJQ9B8N0dAdZ39HDyu1drNzRxUNLt9MVjA75mrLiAEUBP3uS87cMpbw4wNmTazhnag0LplRzUkMZBQOarZxzrNjexdOrd7Ni+wHKiwuoGlNIVWkhNWMLaSgvpqG8iHHlxVSUFHj6fyKSTqmaQg7cp5A3SWFucyU3XX4K9WVF1JUVU19WREN58RE/aLNF1ZhCqobZDtlYWcJfn9NyzHKlhQGaawI015Ry5qTqw45FYnG6+iJ0BRN9HZWlBdSOLUqtJxuMxGjf18vmzl46u8PJzvU44Zhj7a6DvLyhkydX7QLA7zMmVBbTUjOGqtJCXt3Yya6uEGYwuXYMfeEYe3vChKLxd//cpQXMnljJnImVzG6qpKG8mNJCP6WFfooK/PSFY3QFIxwMRghHHU1VJeo7kazV2RMm4DPKS7L/Izf7Ixwhk2rGcM05YzIdRtYr8PuoGVt0xLbP4gI/0+rLmFZ/5BrP9v19vLZxL+s7utnc2cvmzh7W7e7mzElVXDCjgfNPrjts+uC+cCzZrBdkZ1eQnQeCrNl1kKVbD/DcmrUMt4XT7zMaK0uoHlNIKBonFI0RisSpLSti/uRqzm6p5qyWaspLAkRijnAsTizmKC3yH1ajERlp/VNc5ELtN2+SgqTPhMoSFs1tHHb5kkI/zTWJforBukNRVmw7wL7eML3hGL3hGMFIjNLCRH9MWXGAgM/Htv29bNnby5a9fezvDVMb8FNc4KMw4KN9bx93vriJ25ZsAMCMdyWa0kJ/qjlrSt0YptePZXp9GadMKKelVl8m5MR0doepzoGmI1BSkCw3tijA/Ck1J/w+wUiMpVv307p5H8FIjEJ/ImH4fUZvOEZXX4QDfRH2dIdY3n6Ah5fvSCWOlppSzj+5ng/OqGfBlOojjjYTOZLOnjC1OXCPAnicFMzsEuBWwA/8xjn3/UHHfwx8MLlZCtQ75yq9jEnyU3GBn/lTaoadYPrCMdZ3dPPmln08s3o3d7+2hTtf2sS48mJuvPgkrjyjSSOtZNg6e0K0DFETzkaeJQUz8wM/Bz4EtAOvm9kDzrmV/WWcc18eUP4GYK5X8Ygcj5JCP6c2VnBqYwXXnNNCMBLjhbV7+Okz6/jKfcu4/cVNfP2ymSycXpvpUCUHdHaHc+IeBfC2pnA2sM45twHAzO4BLgdWHqH8YuCbHsYj8p4VF/i5aFYDF8yo56HlO/jBo6v51H+8ypS6MSyYUsP8ydUsmFJDQ7k397pI7upL9oXlynQ3XiaFRmDrgO12YP5QBc1sEjAZeNrDeEROmM9nfGz2BD58SgO/f30rz6zezYNvbee/X90CwIIp1Xxy/iQ+fMq4rB/uLOnRP8WF+hSOz9XAfc652FAHzex64HqA5ubmdMYlMqSigJ9rzmnhmnNaiMUdK7d38dya3fy+dSs33N1G7dhCrjpzIlefNVGjl/JcLt24Bt4mhW3AxAHbTcl9Q7ka+NyR3sg5dxtwGySmuRipAEVGgt9nnNZUwWlNFfzj+dN4ft0efvfKZm5bsp5fPree+ZOrufrsiVx66vjUTYCSP/prCrmwwA54mxReB6ab2WQSyeBq4K8GFzKzGUAV8LKHsYikhc9nnHdSHeedVMeuriD3vdHOva1b+fLvl/K1P73NuVNr+EDyuGoQ+aG/plCb7zUF51zUzD4PPEZiSOrtzrkVZnYT0OqceyBZ9GrgHpdrM/OJHENDeTGf++A0/uG8qbyysZNHlu9kydoOnlq9G0jc/3DBjAYumlnPWZOrdVf1KNWZQ2spgMd9Cs65h4GHB+37xqDtb3kZg0im+XzGuVNrOXdqYvjq5s4enlvTwdOrd/Nfr27m9hc3UlYc4LJTx7N4fjOzmypyYjoEGZ7O7hBFAR+lhbnRdJgtHc0ieaN/Hq5rzmmhNxzl+bV7eGLlLh5ctp3ft25l1vhyFs9v5sq5jYwp0p9orkvczVyUM4le9VWRDCotDPDhU8bxo7+Yzatfu5DvLDoVgH/989ucc/NT/ODR1ew+GMxwlHIiEjeu5UbTEaimIJI1yooL+NSCSXxyfjNtW/fz6yUb+MVz6/nN8xv50CkNGLCvN5z6kPnBVbNprCzJdNhyDJ09Iepy5G5mUE1BJOuYGWc0V/GLT53JMzeezyfOauK1jXtZsb2LYCROU1Upy9oPsOjnL/L2tgOZDleOIZdmSAXVFESyWkvtGL6z6DS+s+i0w/av2XWQz9zxOp/41cv8dPFcLpzZkKEI5Wicczk1QyooKYjkpJMayrj/c+fyN79t5W/vamXRnEYKAz4iMUfcORZOq+XKM7xdZlaOrTsUJRyNq09BRLxXX1bMPdcv4Kt/XM5zazoI+I2Az0ckFuf+tm3c8/oWbrr8VGaOL890qHmr/8Y1NR+JSFqUFgb4yeLDZ5yPxx33vdHOzY+s4iM/fYFrz23hyx86ibEa3pp2uXbjGqijWWTU8fmMT5w1kadvPJ9PzJvI7S9u5NJbl/DKhs5Mh5Z3OruTM6TmUE1BSUFklKoaU8jNV57GvX93Dj4zFv/6Fb790EqCkSEnIxYPqKYgIlnnrJZqHvni+/nrBZP4jxc2cumtz/Or59azaU9PpkMb9fprCrmywA6oT0EkL5QWBrjp8lO5eNY4bnl0NTc/knjMGFfGBTPqmT2xktMaKxhfUawRSyOosyfM2KJATk2ZrqQgkkcWTq9l4fSFtO/r5fEVu3h0xU5+tWQDsXhikuKaMYVMqCwhFnfE4o5oPE5xgZ/qMYVUlhZSURJgf2+EnQeC7OwK0heOcf0HpvDZhZMJaJbXd8m1KS5ASUEkLzVVlXLdwslct3AywUiMlTu6eHvbAZa3H6CjO0TA5yPgM/w+ozccZV9vhK17e9nfF6GypIBxFcXMm1RFZ0+Ymx9ZzYPLtnPLx0/nlAkVmf7RskpnTyinmo5ASUEk7xUX+DmjuYozmquO+7XOOR5evpNvPrCCj/3sRT59TgtXzG3klAnl+HxqhursDtNUVZrpMI6LkoKIvGdmxv84fTzvm1bD9x5exR0vbeT2FzdSX1bEhTPruWBGAwun1VKSI2sJjLTOnjBzJlZmOozjoqQgIiessjQxa+v/umQGz76TWEDowaU7uPu1rRQFfCycVstFsxr48Cnjcq455Xh1h6I8+vZO/ty2jY6DIerLcuceBQDLtVUw582b51pbWzMdhogcQzga57WNe3ly1S6eXLWL9n19FBf4uOrMJv5m4ZScXKPaOceurhCVpQWHjSja3NnDC+v28PyaPTy7ZjfBSJzm6lIWzZnAZ943maosSIRm9oZzbt4xyykpiIjXnHOs3NHFXS9t5v62bUTicS45ZRx/Nb+Zc6fW4h/Q/xCNxXl+3R5e27iXcDRONBYnEndMrx/LNee0HFYWIBSNcW9rO/G4o7m6lInVpTRVlYz4MNA3t+zj2w+tpG3LfgCqSgtoKC+mJxxl694+ACZUFHPhzAYWzW3kjObKrBreq6QgIllpd1eQO1/axH+9spmuYJT6siI+OnsC75tWw5I1e3ho2Xb2dIcJ+IyigI+A34ffZ+ztCXP25GpuvXoO4ysSiwut3XWQL97zFit3dB12joDP+OjsCfz9eVM5eVxZav++njAPv72DNTsP4vMZfjP8fqO5upT3T6ujuebdncLt+3q55dF3eHDpdurKirjufZOJxePs7Aqy80CIgM84d1oNC6fVMrl2TFYlgoGUFEQkqwUjMZ5evZs/t23j2Xc6CMfiFAZ8XDSznkVzGjn/5HoKA4fuffjTm+3865/fpiDg4/tXns7OA33c/MhqxhQFuOXjpzN7YgVb9/aydW8fbVv2cW9rO32RGBfNrOeimQ08uWoXz63pIBJzlBUnulNjcUc05gjH4gA0V5dy7tQa4s6xdW8fW/f1sn1/H4UBH9e/fwp/d97UnF03W0lBRHLGgd4IbVv3Mbe5ioqSgiOW27inhy/c3cby5IpzHzy5jluuOp36suJ3ld3XE+a3L2/izpc2sb83wrjyYj42ZwKXz5nArPHlqW/0zjk27OnhhbV7eH7tHl7d2ElRwE9zdQkTq0tpqRnDX541kQk5vvSpkoKIjErhaJxfPreeurIirj5r4jGba3rDUTZ09DBzfPm7+iPyyXCTQm7Wg0QkbxUGfHzhwunDLl9aGODURt1pPVyarERERFKUFEREJEVJQUREUpQUREQkRUlBRERSlBRERCRFSUFERFKUFEREJCXn7mg2swPA2iEOVQAHjrJv8PH+7aHK1AJ73kN4Q8Uw3DJHim+o7aGen2jsR4vtWMd17Q/t8yr+93rtB2978buTyWs/8Hk+XvujxTf4+CTnXN0x3805l1MP4Lbh7h+4b/Dx/u2hygCtIxnbe4n/aNtHiPmEYh9O/Lr2R7/2Xsb/Xq99On53Mnnt0xF/Nl/7E4n/SI9cbD568Dj2P3iU4w8Oo8zxGs7rhxv/0baHen6isQ/nPXTtc+/aD972Iv5MXvvhnv9ocvnaD+c9juscOdd8lA5m1uqGMXFUNsrl2EHxZ1Iuxw65HX82xZ6LNYV0uC3TAZyAXI4dFH8m5XLskNvxZ03sqimIiEiKagoiIpIy6pOCmd1uZrvN7O338NozzWy5ma0zs5/YgNU8zOwGM1ttZivM7AcjG3XqHCMeu5l9y8y2mdlbycdlIx95KgZPrn3y+I1m5sysduQiPuz9vbj23zazZcnr/riZTRj5yFMxeBH/D5O/88vM7H4zqxz5yD2L/S+Sf6txM/Ok7f5E4j7C+33azNYmH58esP+ofxsn7L0Og8qVB/AB4Azg7ffw2teABYABjwCXJvd/EHgSKEpu1+dQ7N8C/jlXr33y2ETgMWAzUJsrsQPlA8p8AfhlLl174GIgkHx+C3BLDsU+EzgZeBaYl01xJ2NqGbSvGtiQ/Lcq+bzqaD/jSD1GfU3BObcE2Dtwn5lNNbNHzewNM3vezGYMfp2ZjSfxR/yKS/xP3AUsSh7+B+D7zrlQ8hy7cyj2tPEw/h8D/xPwrEPMi9idc10Dio7Jwfgfd85Fk0VfAZpyKPZVzrl3vIj3ROM+gg8DTzjn9jrn9gFPAJek42971CeFI7gNuME5dybwz8C/D1GmEWgfsN2e3AdwEvB+M3vVzJ4zs7M8jfZwJxo7wOeTTQC3m1mVd6EO6YTiN7PLgW3OuaVeBzqEE772ZvZdM9sKfBL4hoexDmUkfnf6XUfiW2q6jGTs6TScuIfSCGwdsN3/s3j+M+bdGs1mNhY4F/jDgKa4ouN8mwCJat0C4CzgXjObkszcnhmh2H8BfJvEt9RvA/9G4g/ccycav5mVAl8j0YyRViN07XHOfR34upn9C/B54JsjFuRRjFT8yff6OhAFfjcy0R3zfCMWezodLW4z+wzwxeS+acDDZhYGNjrnrkh3rAPlXVIgUTva75xidBr+AAAEqklEQVSbM3CnmfmBN5KbD5D48BxYPW4CtiWftwN/SiaB18wsTmLukg4vA2cEYnfO7Rrwul8DD3kZ8CAnGv9UYDKwNPlH1gS8aWZnO+d2Znnsg/0OeJg0JQVGKH4zuxb4CHCh11+CBhjpa58uQ8YN4Jy7A7gDwMyeBa51zm0aUGQbcP6A7SYSfQ/b8Ppn9KLDJdseQAsDOn+Al4C/SD43YPYRXje4Q+ey5P6/B25KPj+JRDXPciT28QPKfBm4J5eu/aAym/Coo9mjaz99QJkbgPty6doDlwArgTov4/by9wYPO5rfa9wcuaN5I4lO5qrk8+rh/Iwn/DN4/Z+b6QdwN7ADiJD4hv9ZEt82HwWWJn/Jv3GE184D3gbWAz/j0M1+hcB/JY+9CVyQQ7H/J7AcWEbi29V4L2L3Kv5BZTbh3egjL679H5P7l5GYj6Yxl649sI7EF6C3kg9PRk95FPsVyfcKAbuAx7IlboZICsn91yWv+TrgM8fzt3EiD93RLCIiKfk6+khERIagpCAiIilKCiIikqKkICIiKUoKIiKSoqQgo4KZdaf5fL8xs1kj9F4xS8yc+raZPXis2UfNrNLM/nEkzi0ymIakyqhgZt3OubEj+H4Bd2jyN08NjN3Mfguscc599yjlW4CHnHOnpiM+yS+qKcioZWZ1ZvZHM3s9+Xhfcv/ZZvaymbWZ2UtmdnJy/7Vm9oCZPQ08ZWbnm9mzZnafJdYR+F3/3PXJ/fOSz7uTE90tNbNXzKwhuX9qcnu5mX1nmLWZlzk0+d9YM3vKzN5MvsflyTLfB6Ymaxc/TJb9SvJnXGZm/2cEL6PkGSUFGc1uBX7snDsL+Djwm+T+1cD7nXNzScxU+r0BrzkDuMo5d15yey7wJWAWMAV43xDnGQO84pybDSwB/nbA+W91zp3G4TNbDik5l8+FJO40BwgCVzjnziCxhse/JZPSV4H1zrk5zrmvmNnFwHTgbGAOcKaZfeBY5xMZSj5OiCf54yJg1oAZKsuTM1dWAL81s+kkZostGPCaJ5xzA+fEf8051w5gZm+RmNvmhUHnCXNoYsE3gA8ln5/Dobnu/xv40RHiLEm+dyOwisTc+ZCY2+Z7yQ/4ePJ4wxCvvzj5aEtujyWRJJYc4XwiR6SkIKOZD1jgnAsO3GlmPwOecc5dkWyff3bA4Z5B7xEa8DzG0H8zEXeoc+5IZY6mzzk3Jzk1+GPA54CfkFhzoQ440zkXMbNNQPEQrzfgZufcr47zvCLvouYjGc0eJzEbKQBm1j+FcQWHphu+1sPzv0Ki2Qrg6mMVds71klim80YzC5CIc3cyIXwQmJQsehAoG/DSx4DrkrUgzKzRzOpH6GeQPKOkIKNFqZm1D3j8E4kP2HnJzteVJKY8B/gBcLOZteFtbflLwD+Z2TISC6kcONYLnHNtJGZRXUxizYV5ZrYcuIZEXwjOuU7gxeQQ1h865x4n0Tz1crLsfRyeNESGTUNSRTySbA7qc845M7saWOycu/xYrxPJJPUpiHjnTOBnyRFD+0nTsqciJ0I1BRERSVGfgoiIpCgpiIhIipKCiIikKCmIiEiKkoKIiKQoKYiISMr/B9prDkGegvV8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the learning rate\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:06 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.489732</th>\n",
       "    <th>0.396303</th>\n",
       "    <th>0.828000</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit with tuned learning rate from above\n",
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:21 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.389068</th>\n",
       "    <th>0.302034</th>\n",
       "    <th>0.882667</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# unfreeze the last 2 layers, don't unfreeze the whole thing\n",
    "# unfreeze in an iterative process. Train with unfrozen last two layers\n",
    "# then train again with the last 3 layers, then train again with the whole \n",
    "# thing\n",
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4), 1e-2), moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 03:55 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.329627</th>\n",
       "    <th>0.259485</th>\n",
       "    <th>0.900000</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4), 5e-3), moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 10:58 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.298484</th>\n",
       "    <th>0.248855</th>\n",
       "    <th>0.901333</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.294350</th>\n",
       "    <th>0.244838</th>\n",
       "    <th>0.900667</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# unfreeze whole thing\n",
    "# for training RNN, it really helps to decrease the momentum a little bit\n",
    "# which is what the moms parameter does\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4), 1e-3), moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
